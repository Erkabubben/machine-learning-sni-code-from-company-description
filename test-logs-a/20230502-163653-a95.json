{
  "input_parameters": {
    "name_of_data_file": "nlp_applied_data_0",
    "name_of_custom_stopwords_file": "custom_stopwords_0",
    "data_limit": 900000,
    "use_full_SNI_numbers": false,
    "random_state": 42,
    "naive_bayes": {
      "on": true,
      "alpha": 0.017
    },
    "svm": {
      "on": false,
      "C": 1,
      "class_weight": "balanced"
    },
    "pipeline": {
      "on": false
    },
    "split_training_and_testing_data": {
      "test_size": 0.15,
      "stratify": true
    },
    "under_sampling": {
      "on": true,
      "sampling_strategy": "not minority"
    },
    "filter_low_occuring_labels": {
      "on": true
    },
    "random_oversampling": {
      "on": false,
      "sampling_strategy": "all"
    },
    "SMOTE": {
      "on": false,
      "k_neighbors": 1,
      "sampling_strategy": "all"
    },
    "combine_under_and_oversampling": {
      "on": false,
      "over_sampling_strategy": "minority",
      "under_sampling_strategy": "majority"
    },
    "testing_methods": {
      "train_test_split": true,
      "5-fold": false
    }
  },
  "model_test_results": {
    "naive_bayes": {
      "split": {
        "accuracy": 0.5611548215098511,
        "classification_report": "              precision    recall  f1-score   support\n\n           0       0.60      0.65      0.62      1091\n           1       0.70      0.59      0.64       582\n           2       0.82      0.43      0.56        63\n           4       0.00      0.00      0.00         5\n           5       0.50      0.12      0.19        58\n           6       0.57      0.20      0.30        20\n           7       0.44      0.30      0.35       399\n           8       0.70      0.31      0.43       100\n           9       0.00      0.00      0.00         6\n          10       0.30      0.06      0.11        93\n          11       0.00      0.00      0.00        59\n          12       0.50      0.04      0.07        25\n          13       0.55      0.27      0.37       340\n          14       0.00      0.00      0.00        41\n          15       0.60      0.35      0.44       225\n          16       0.00      0.00      0.00         4\n          17       0.26      0.05      0.08        99\n          18       0.00      0.00      0.00        19\n          19       0.47      0.16      0.24       160\n          20       0.69      0.20      0.31       119\n          21       0.00      0.00      0.00        45\n          22       0.54      0.53      0.53       931\n          23       0.07      0.02      0.03       172\n          24       0.10      0.01      0.02       112\n          25       0.23      0.07      0.11       345\n          26       0.00      0.00      0.00       111\n          27       0.45      0.05      0.10        91\n          28       0.35      0.06      0.10       190\n          29       0.59      0.17      0.27       278\n          30       0.37      0.23      0.28       563\n          31       0.58      0.58      0.58       295\n          32       0.00      0.00      0.00        14\n          33       0.44      0.12      0.19        34\n          34       0.55      0.22      0.31       110\n          35       0.00      0.00      0.00        16\n          36       0.47      0.30      0.37      2735\n          37       0.35      0.07      0.12       366\n          38       0.57      0.75      0.65      7547\n          39       0.66      0.76      0.71      2267\n          40       0.38      0.40      0.39      4783\n          41       0.55      0.62      0.59      5297\n          42       0.70      0.75      0.72      2229\n          43       0.64      0.39      0.48       121\n          44       1.00      0.11      0.20        37\n          45       0.54      0.25      0.34       459\n          46       0.78      0.13      0.22        54\n          47       0.57      0.40      0.47       655\n          48       0.74      0.81      0.77      3068\n          49       0.44      0.20      0.28       800\n          50       0.59      0.57      0.58       996\n          51       0.00      0.00      0.00        19\n          52       0.43      0.11      0.17       113\n          53       0.58      0.59      0.58      4879\n          54       0.29      0.11      0.16       421\n          55       0.40      0.26      0.32      3714\n          56       0.96      0.81      0.88        27\n          57       0.62      0.30      0.40       758\n          58       0.60      0.81      0.69      9195\n          59       0.77      0.70      0.74      3232\n          60       0.47      0.59      0.52      9407\n          61       0.54      0.52      0.53      4653\n          62       0.45      0.33      0.38       469\n          63       0.41      0.33      0.36      1203\n          64       0.43      0.33      0.37      2038\n          65       0.86      0.68      0.76       130\n          66       0.34      0.13      0.19       749\n          67       0.55      0.31      0.40      1015\n          68       0.59      0.39      0.47       284\n          69       0.62      0.27      0.38       112\n          70       0.61      0.52      0.56      1378\n          71       0.34      0.11      0.17       397\n          72       0.00      0.00      0.00        11\n          73       0.50      0.40      0.45      1718\n          74       0.74      0.83      0.78      3209\n          75       0.68      0.57      0.62       242\n          76       0.57      0.50      0.54       327\n          77       0.50      0.53      0.52      1234\n          78       1.00      0.03      0.06        31\n          79       0.00      0.00      0.00        34\n          80       0.51      0.47      0.49       976\n          81       0.42      0.14      0.20        37\n          82       0.41      0.09      0.15       167\n          83       0.73      0.70      0.72      1866\n\n    accuracy                           0.56     92274\n   macro avg       0.46      0.30      0.33     92274\nweighted avg       0.55      0.56      0.54     92274\n"
      },
      "5_fold_cv": {
        "accuracy": 0.3302866638969672,
        "classification_report": "              precision    recall  f1-score   support\n\n           0       0.44      0.41      0.43        29\n           1       0.57      0.41      0.48        29\n           2       0.78      0.62      0.69        29\n           4       0.52      0.48      0.50        29\n           5       0.47      0.48      0.47        29\n           6       0.57      0.59      0.58        29\n           7       0.47      0.31      0.38        29\n           8       0.35      0.48      0.41        29\n           9       0.79      0.76      0.77        29\n          10       0.45      0.34      0.39        29\n          11       0.39      0.48      0.43        29\n          12       0.35      0.28      0.31        29\n          13       0.44      0.24      0.31        29\n          14       0.14      0.10      0.12        29\n          15       0.41      0.31      0.35        29\n          16       0.38      0.48      0.42        29\n          17       0.11      0.17      0.14        29\n          18       0.38      0.62      0.47        29\n          19       0.16      0.10      0.12        29\n          20       0.20      0.14      0.16        29\n          21       0.50      0.38      0.43        29\n          22       0.11      0.07      0.08        29\n          23       0.26      0.38      0.31        29\n          24       0.28      0.17      0.21        29\n          25       0.05      0.03      0.04        29\n          26       0.16      0.17      0.17        29\n          27       0.08      0.07      0.08        29\n          28       0.34      0.38      0.36        29\n          29       0.18      0.14      0.16        29\n          30       0.13      0.21      0.16        29\n          31       0.55      0.38      0.45        29\n          32       0.37      0.62      0.46        29\n          33       0.74      0.48      0.58        29\n          34       0.19      0.17      0.18        29\n          35       0.59      0.59      0.59        29\n          36       0.24      0.28      0.26        29\n          37       0.06      0.03      0.04        29\n          38       0.28      0.17      0.21        29\n          39       0.30      0.45      0.36        29\n          40       0.05      0.03      0.04        29\n          41       0.05      0.03      0.04        29\n          42       0.20      0.24      0.22        29\n          43       0.45      0.45      0.45        29\n          44       0.89      0.59      0.71        29\n          45       0.78      0.24      0.37        29\n          46       0.46      0.38      0.42        29\n          47       0.47      0.62      0.54        29\n          48       0.45      0.59      0.51        29\n          49       0.17      0.17      0.17        29\n          50       0.41      0.55      0.47        29\n          51       0.13      0.14      0.13        29\n          52       0.44      0.55      0.49        29\n          53       0.18      0.24      0.21        29\n          54       0.14      0.10      0.12        29\n          55       0.14      0.28      0.19        29\n          56       0.76      0.76      0.76        29\n          57       0.12      0.14      0.13        29\n          58       0.18      0.52      0.27        29\n          59       0.43      0.45      0.44        29\n          60       0.00      0.00      0.00        29\n          61       0.05      0.07      0.06        29\n          62       0.21      0.17      0.19        29\n          63       0.34      0.34      0.34        29\n          64       0.06      0.03      0.04        29\n          65       0.66      0.93      0.77        29\n          66       0.03      0.03      0.03        29\n          67       0.46      0.45      0.46        29\n          68       0.36      0.31      0.33        29\n          69       0.60      0.41      0.49        29\n          70       0.28      0.24      0.26        29\n          71       0.13      0.10      0.12        29\n          72       0.31      0.28      0.29        29\n          73       0.14      0.10      0.12        29\n          74       0.46      0.62      0.53        29\n          75       0.29      0.38      0.33        29\n          76       0.35      0.41      0.38        29\n          77       0.29      0.28      0.28        29\n          78       0.45      0.34      0.39        29\n          79       0.84      0.55      0.67        29\n          80       0.18      0.07      0.10        29\n          81       0.60      0.41      0.49        29\n          82       0.53      0.34      0.42        29\n          83       0.46      0.45      0.46        29\n\n    accuracy                           0.33      2407\n   macro avg       0.35      0.33      0.33      2407\nweighted avg       0.35      0.33      0.33      2407\n"
      }
    }
  }
}