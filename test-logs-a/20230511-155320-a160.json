{
  "input_parameters": {
    "name_of_data_file": "nlp_applied_data_0",
    "name_of_custom_stopwords_file": "custom_stopwords_0",
    "data_limit": 900000,
    "use_full_SNI_numbers": false,
    "random_state": 5,
    "naive_bayes": {
      "on": false,
      "alpha": 0.017
    },
    "svm": {
      "on": true,
      "C": 0.18,
      "class_weight": null
    },
    "pipeline": {
      "on": false
    },
    "split_training_and_testing_data": {
      "test_size": 0.15,
      "stratify": true
    },
    "under_sampling": {
      "on": false,
      "sampling_strategy": "all"
    },
    "filter_low_occuring_labels": {
      "on": true
    },
    "random_oversampling": {
      "on": false,
      "sampling_strategy": "all"
    },
    "SMOTE": {
      "on": false,
      "k_neighbors": 1,
      "sampling_strategy": "all"
    },
    "combine_under_and_oversampling": {
      "on": false,
      "over_sampling_strategy": "minority",
      "under_sampling_strategy": "majority"
    },
    "testing_methods": {
      "train_test_split": true,
      "5-fold": false
    }
  },
  "model_test_results": {
    "svm": {
      "split": {
        "accuracy": 0.6011119058456337,
        "classification_report": "              precision    recall  f1-score   support\n\n           0       0.64      0.75      0.69      1091\n           1       0.66      0.69      0.68       582\n           2       0.72      0.75      0.73        63\n           4       0.00      0.00      0.00         5\n           5       0.48      0.36      0.41        58\n           6       0.47      0.40      0.43        20\n           7       0.58      0.42      0.49       399\n           8       0.68      0.50      0.58       100\n           9       1.00      0.33      0.50         6\n          10       0.45      0.22      0.29        93\n          11       0.33      0.03      0.06        59\n          12       0.60      0.12      0.20        25\n          13       0.53      0.34      0.42       340\n          14       0.40      0.10      0.16        41\n          15       0.50      0.40      0.45       225\n          16       0.00      0.00      0.00         4\n          17       0.27      0.04      0.07        99\n          18       0.00      0.00      0.00        19\n          19       0.59      0.36      0.45       160\n          20       0.57      0.33      0.42       119\n          21       0.43      0.13      0.20        45\n          22       0.51      0.56      0.54       931\n          23       0.25      0.05      0.09       172\n          24       0.29      0.04      0.08       112\n          25       0.32      0.11      0.17       345\n          26       0.75      0.05      0.10       111\n          27       0.36      0.11      0.17        91\n          28       0.55      0.24      0.34       190\n          29       0.73      0.26      0.38       278\n          30       0.47      0.27      0.34       563\n          31       0.69      0.74      0.71       295\n          32       0.50      0.21      0.30        14\n          33       0.31      0.12      0.17        34\n          34       0.49      0.33      0.39       110\n          35       0.00      0.00      0.00        16\n          36       0.50      0.42      0.45      2735\n          37       0.40      0.09      0.14       366\n          38       0.62      0.74      0.67      7547\n          39       0.70      0.79      0.74      2267\n          40       0.45      0.44      0.44      4783\n          41       0.57      0.65      0.61      5297\n          42       0.73      0.80      0.76      2229\n          43       0.57      0.50      0.53       121\n          44       0.63      0.32      0.43        37\n          45       0.56      0.36      0.44       459\n          46       0.94      0.28      0.43        54\n          47       0.60      0.63      0.62       655\n          48       0.80      0.85      0.82      3068\n          49       0.51      0.23      0.31       800\n          50       0.57      0.65      0.61       996\n          51       0.00      0.00      0.00        19\n          52       0.47      0.17      0.25       113\n          53       0.59      0.68      0.63      4879\n          54       0.47      0.08      0.13       421\n          55       0.46      0.35      0.40      3714\n          56       0.88      0.78      0.82        27\n          57       0.66      0.34      0.44       758\n          58       0.65      0.82      0.72      9195\n          59       0.73      0.75      0.74      3232\n          60       0.54      0.59      0.56      9407\n          61       0.56      0.57      0.56      4653\n          62       0.49      0.38      0.43       469\n          63       0.47      0.35      0.40      1203\n          64       0.52      0.34      0.41      2038\n          65       0.80      0.82      0.81       130\n          66       0.41      0.17      0.25       749\n          67       0.56      0.36      0.44      1015\n          68       0.58      0.50      0.54       284\n          69       0.60      0.36      0.45       112\n          70       0.62      0.57      0.59      1378\n          71       0.53      0.18      0.27       397\n          72       0.00      0.00      0.00        11\n          73       0.54      0.44      0.49      1718\n          74       0.76      0.87      0.81      3209\n          75       0.63      0.59      0.61       242\n          76       0.60      0.58      0.59       327\n          77       0.54      0.62      0.58      1234\n          78       0.58      0.23      0.33        31\n          79       0.38      0.15      0.21        34\n          80       0.56      0.52      0.54       976\n          81       0.29      0.05      0.09        37\n          82       0.52      0.19      0.27       167\n          83       0.74      0.74      0.74      1866\n\n    accuracy                           0.60     92274\n   macro avg       0.52      0.38      0.41     92274\nweighted avg       0.59      0.60      0.59     92274\n"
      },
      "5_fold_cv": {
        "accuracy": 0.592483557069891,
        "classification_report": "              precision    recall  f1-score   support\n\n           0       0.60      0.71      0.65      7276\n           1       0.67      0.65      0.66      3878\n           2       0.63      0.64      0.63       423\n           4       0.67      0.06      0.11        33\n           5       0.52      0.41      0.46       384\n           6       0.48      0.45      0.46       136\n           7       0.54      0.41      0.47      2658\n           8       0.68      0.50      0.57       670\n           9       0.59      0.44      0.51        43\n          10       0.43      0.19      0.27       622\n          11       0.41      0.02      0.04       395\n          12       0.45      0.09      0.15       167\n          13       0.51      0.34      0.40      2268\n          14       0.43      0.09      0.15       276\n          15       0.55      0.43      0.49      1503\n          16       0.00      0.00      0.00        29\n          17       0.42      0.07      0.12       658\n          18       0.33      0.02      0.03       127\n          19       0.48      0.32      0.38      1067\n          20       0.57      0.34      0.43       791\n          21       0.39      0.09      0.14       303\n          22       0.51      0.56      0.53      6207\n          23       0.35      0.06      0.11      1146\n          24       0.33      0.06      0.10       745\n          25       0.31      0.10      0.15      2301\n          26       0.43      0.04      0.07       739\n          27       0.45      0.11      0.18       604\n          28       0.49      0.22      0.30      1266\n          29       0.61      0.22      0.32      1856\n          30       0.46      0.26      0.33      3755\n          31       0.64      0.68      0.66      1966\n          32       0.53      0.26      0.35        92\n          33       0.40      0.18      0.25       229\n          34       0.48      0.30      0.37       732\n          35       0.25      0.01      0.02       107\n          36       0.48      0.40      0.44     18236\n          37       0.42      0.09      0.15      2439\n          38       0.61      0.73      0.67     50310\n          39       0.67      0.78      0.72     15116\n          40       0.43      0.44      0.44     31886\n          41       0.56      0.64      0.60     35313\n          42       0.73      0.80      0.76     14857\n          43       0.51      0.49      0.50       810\n          44       0.47      0.29      0.35       245\n          45       0.56      0.33      0.42      3058\n          46       0.64      0.18      0.29       357\n          47       0.58      0.62      0.60      4364\n          48       0.79      0.84      0.81     20450\n          49       0.48      0.22      0.30      5334\n          50       0.57      0.63      0.60      6638\n          51       0.56      0.04      0.07       129\n          52       0.45      0.16      0.24       753\n          53       0.58      0.67      0.62     32525\n          54       0.40      0.08      0.13      2804\n          55       0.45      0.34      0.39     24761\n          56       0.96      0.82      0.88       182\n          57       0.63      0.32      0.42      5054\n          58       0.65      0.81      0.72     61298\n          59       0.73      0.75      0.74     21544\n          60       0.53      0.58      0.55     62710\n          61       0.55      0.55      0.55     31019\n          62       0.48      0.36      0.41      3127\n          63       0.49      0.37      0.42      8021\n          64       0.49      0.33      0.40     13585\n          65       0.81      0.85      0.83       865\n          66       0.44      0.19      0.26      4991\n          67       0.54      0.36      0.43      6764\n          68       0.55      0.50      0.53      1893\n          69       0.56      0.37      0.45       748\n          70       0.61      0.58      0.59      9186\n          71       0.47      0.18      0.26      2646\n          72       0.00      0.00      0.00        73\n          73       0.54      0.43      0.48     11450\n          74       0.74      0.87      0.80     21395\n          75       0.61      0.56      0.58      1615\n          76       0.62      0.56      0.59      2180\n          77       0.53      0.58      0.55      8230\n          78       0.55      0.15      0.24       208\n          79       0.51      0.14      0.22       230\n          80       0.53      0.50      0.51      6506\n          81       0.23      0.11      0.14       247\n          82       0.56      0.17      0.26      1116\n          83       0.73      0.73      0.73     12438\n\n    accuracy                           0.59    615158\n   macro avg       0.52      0.37      0.40    615158\nweighted avg       0.58      0.59      0.58    615158\n"
      }
    }
  }
}