{
  "input_parameters": {
    "name_of_data_file": "nlp_applied_data_0",
    "name_of_custom_stopwords_file": "custom_stopwords_0",
    "data_limit": 900000,
    "use_full_SNI_numbers": false,
    "random_state": 42,
    "naive_bayes": {
      "on": false,
      "alpha": 1
    },
    "svm": {
      "on": true,
      "C": 0.18,
      "class_weight": null
    },
    "pipeline": {
      "on": false
    },
    "split_training_and_testing_data": {
      "test_size": 0.15,
      "stratify": true,
      "on": true
    },
    "under_sampling": {
      "on": false,
      "sampling_strategy": "all"
    },
    "filter_low_occuring_labels": {
      "on": true
    },
    "random_oversampling": {
      "on": false,
      "sampling_strategy": "minority"
    },
    "SMOTE": {
      "on": true,
      "k_neighbors": 10,
      "sampling_strategy": "not minority"
    },
    "combine_under_and_oversampling": {
      "on": false,
      "over_sampling_strategy": "minority",
      "under_sampling_strategy": "majority"
    },
    "5-fold-solution": {
      "on": false
    }
  },
  "model_test_results": {
    "svm": {
      "split": {
        "accuracy": 0.5095259769815983,
        "classification_report": "              precision    recall  f1-score   support\n\n           0       0.56      0.73      0.63      1091\n           1       0.51      0.75      0.60       582\n           2       0.46      0.76      0.57        63\n           4       0.03      0.20      0.06         5\n           5       0.22      0.57      0.32        58\n           6       0.18      0.50      0.26        20\n           7       0.28      0.64      0.39       399\n           8       0.37      0.78      0.50       100\n           9       0.31      0.67      0.42         6\n          10       0.13      0.41      0.19        93\n          11       0.05      0.29      0.08        59\n          12       0.06      0.28      0.09        25\n          13       0.25      0.57      0.35       340\n          14       0.09      0.32      0.14        41\n          15       0.28      0.53      0.37       225\n          16       0.00      0.00      0.00         4\n          17       0.11      0.32      0.17        99\n          18       0.14      0.47      0.21        19\n          19       0.22      0.43      0.29       160\n          20       0.20      0.53      0.29       119\n          21       0.08      0.31      0.13        45\n          22       0.42      0.55      0.48       931\n          23       0.09      0.27      0.13       172\n          24       0.10      0.31      0.15       112\n          25       0.17      0.34      0.22       345\n          26       0.09      0.32      0.14       111\n          27       0.11      0.35      0.16        91\n          28       0.16      0.47      0.24       190\n          29       0.21      0.46      0.29       278\n          30       0.25      0.47      0.33       563\n          31       0.45      0.78      0.57       295\n          32       0.06      0.14      0.09        14\n          33       0.16      0.53      0.24        34\n          34       0.23      0.50      0.32       110\n          35       0.04      0.25      0.07        16\n          36       0.44      0.54      0.48      2735\n          37       0.11      0.36      0.17       366\n          38       0.76      0.43      0.55      7547\n          39       0.71      0.72      0.71      2267\n          40       0.48      0.23      0.31      4783\n          41       0.65      0.45      0.53      5297\n          42       0.76      0.69      0.72      2229\n          43       0.29      0.65      0.40       121\n          44       0.23      0.46      0.31        37\n          45       0.31      0.50      0.39       459\n          46       0.13      0.44      0.21        54\n          47       0.49      0.71      0.58       655\n          48       0.82      0.79      0.81      3068\n          49       0.23      0.42      0.30       800\n          50       0.53      0.62      0.57       996\n          51       0.03      0.16      0.05        19\n          52       0.12      0.45      0.19       113\n          53       0.62      0.44      0.52      4879\n          54       0.13      0.35      0.19       421\n          55       0.42      0.34      0.38      3714\n          56       0.46      0.81      0.59        27\n          57       0.26      0.49      0.34       758\n          58       0.74      0.65      0.69      9195\n          59       0.72      0.77      0.75      3232\n          60       0.69      0.29      0.41      9407\n          61       0.61      0.44      0.51      4653\n          62       0.26      0.50      0.34       469\n          63       0.35      0.48      0.41      1203\n          64       0.40      0.37      0.38      2038\n          65       0.72      0.92      0.81       130\n          66       0.20      0.42      0.27       749\n          67       0.37      0.50      0.42      1015\n          68       0.33      0.66      0.44       284\n          69       0.19      0.62      0.29       112\n          70       0.49      0.64      0.56      1378\n          71       0.14      0.32      0.19       397\n          72       0.00      0.00      0.00        11\n          73       0.40      0.51      0.45      1718\n          74       0.79      0.77      0.78      3209\n          75       0.37      0.64      0.47       242\n          76       0.40      0.63      0.49       327\n          77       0.44      0.58      0.50      1234\n          78       0.12      0.32      0.17        31\n          79       0.14      0.62      0.23        34\n          80       0.43      0.59      0.50       976\n          81       0.05      0.22      0.09        37\n          82       0.15      0.42      0.22       167\n          83       0.69      0.75      0.72      1866\n\n    accuracy                           0.51     92274\n   macro avg       0.32      0.49      0.36     92274\nweighted avg       0.58      0.51      0.52     92274\n"
      }
    }
  }
}